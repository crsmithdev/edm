# First Real Training Run Configuration
# Optimized for RTX 5070 (12GB VRAM), 356 annotations, 2-3 hour runtime
# Conservative settings prioritizing reliability over performance

# Model Configuration
model:
  backbone: "mert-95m"  # 95M params fits in 12GB, good quality/speed
  freeze_backbone: true  # Only train heads (faster, less prone to overfit)
  unfreeze_after_epoch: 15  # Unfreeze last 2 layers after warmup

  # Task heads (enable what you have labels for)
  heads:
    boundary: true       # Structure boundaries (main task)
    beat: true          # Beat detection (if you have beat grids)
    energy: false       # Skip for first run (fewer tasks = faster debug)
    label: true         # Section labels (intro/drop/etc)

# Dataset Configuration
data:
  annotation_dir: "data/annotations"
  audio_dir: "~/music"  # Audio files location

  # Filtering (conservative first run)
  tier_filter: null     # Use all 356 (no Tier 1 available yet)
  min_confidence: 0.8   # Higher threshold = cleaner data

  # Audio processing
  sample_rate: 24000    # MERT native SR
  duration: 30.0        # 30s clips (full tracks too slow first run)
  frame_rate: 50.0      # MERT default (50 fps)

  # DataLoader
  batch_size: 8         # Conservative for 12GB VRAM
  num_workers: 8        # Match your CPU cores
  prefetch_factor: 2

  # Splits
  train_split: 0.75     # ~267 tracks
  val_split: 0.15       # ~53 tracks
  test_split: 0.10      # ~36 tracks
  seed: 42

# Training Configuration
training:
  num_epochs: 1         # Single epoch test run
  learning_rate: 3e-4   # Higher LR for frozen backbone
  weight_decay: 0.01

  # LR schedule
  scheduler: "onecycle"  # Best for short runs
  warmup_epochs: 3

  # Optimization
  gradient_clip: 1.0
  mixed_precision: true  # fp16 for speed

  # Checkpointing
  save_every: 5         # Every 5 epochs
  eval_every: 1         # Validate every epoch
  log_every: 10         # Log every 10 batches

  # Early stopping
  patience: 10          # Stop if no improvement for 10 epochs
  metric: "val_boundary_f1"  # Primary metric to track

# Loss weights (start balanced, tune later)
loss:
  boundary: 1.0
  beat: 1.0
  label: 0.5           # Lower weight (auxiliary task)

  # Boundary-specific settings
  boundary_tolerance: 3  # Â±3 frames tolerance (~60ms at 50fps)
  use_focal_loss: true   # Handle class imbalance (boundaries are rare)
  focal_gamma: 2.0

# MLflow tracking
mlflow:
  experiment_name: "edm-structure-baseline"
  run_name: "first_real_run_mert95m_30ep"
  tracking_uri: "mlruns"  # Local tracking

# Output
output_dir: "experiments/first_run"
save_best_only: false  # Keep all checkpoints for analysis

# Notes
# Expected runtime: 2-3 hours on RTX 5070
# Expected VRAM: 6-8GB
# Expected val_boundary_f1: >0.6 by epoch 15
#
# Good signs:
# - Training loss decreasing smoothly
# - Val loss tracking train loss (not diverging)
#
# Red flags:
# - Val loss increasing while train decreases (overfitting)
# - Boundary F1 stuck at 0 (broken labels or loss)
# - OOM errors (reduce batch_size to 4)
#
# After successful run:
# 1. Check tensorboard: boundary F1, beat F1, label accuracy
# 2. Inspect predictions: edm analyze --detector ml
# 3. Tune based on results (see docs/training.md)
